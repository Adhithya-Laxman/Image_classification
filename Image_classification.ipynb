{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3N7cp4oajAZAxRT+ubxkl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adhithya-Laxman/Image_classification/blob/main/Image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EEX8bMYrX1Tn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54e48f1d-c25a-4afb-8c5d-f4584e259ee4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.15.8-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.6)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.32-py3-none-any.whl (188 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.31.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.29.2-py2.py3-none-any.whl (215 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.6/215.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.1)\n",
            "Collecting pathtools (from wandb)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=ea0fdc62fb64538e5efb6dcbcb33f8e4aaa326270de49916e20e6da5adcd25b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.32 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.29.2 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.8\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 1 -- Loading the datasets and the packages\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import wandb\n",
        "import random"
      ],
      "metadata": {
        "id": "icEDNYu9ZS2C"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Plotting a sample image for each class\n"
      ],
      "metadata": {
        "id": "5zposwGaauJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the dataset:\n",
        "\n",
        "(X, y),_= fashion_mnist.load_data()\n",
        "(train_images, train_labels) = (X,y)\n",
        "\n",
        "# (X_train, Y_train),(X_test, Y_test) = fashion_mnist.load_data()\n",
        "# # Defining Class Labels:\n",
        "\n",
        "# print(X_train.shape)\n",
        "# print(Y_train.shape)\n",
        "# print(X_test.shape)\n",
        "# print(Y_test.shape)\n",
        "class_labels = [\n",
        "    \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\",\n",
        "    \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\",\n",
        "    \"Bag\", \"Ankle boot\"\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "# Plotting a sample image for each class:\n",
        "\n",
        "plt.figure(figsize=(12,12))\n",
        "for i in range(len(class_labels)):\n",
        "  # Get the image data matching the current class i\n",
        "  ind = np.where(train_labels == i)[0][0]\n",
        "  image  = train_images[ind]\n",
        "  # plot\n",
        "  # plt.title(\"examples\")\n",
        "  plt.subplot(1, len(class_labels), i+1)\n",
        "  plt.imshow(image,cmap = 'gray')\n",
        "  plt.title(class_labels[i])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "yyW9_MKIaMxj",
        "outputId": "5bb023ef-804d-4ab4-db72-23b9dc8ccc69"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x1200 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing dataset"
      ],
      "metadata": {
        "id": "egMHEnG2en8T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import fashion_mnist\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def preprocess_fashion_mnist():\n",
        "    # Load the Fashion-MNIST dataset\n",
        "    (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "    # Flatten and normalize the input data\n",
        "    X_train = X_train.reshape(-1, 28*28)  # Flatten each image to a 1D vector\n",
        "    X_test = X_test.reshape(-1, 28*28)\n",
        "    X_train = X_train.astype('float32') / 255.0  # Normalize pixel values to [0, 1]\n",
        "    X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "    # One-hot encode the labels\n",
        "    num_classes = 10\n",
        "    y_train = np.eye(num_classes)[y_train]  # One-hot encode the training labels\n",
        "    y_test = np.eye(num_classes)[y_test]    # One-hot encode the test labels\n",
        "\n",
        "    # Split the data into training, validation, and test sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=6000, random_state=42)\n",
        "\n",
        "    # Transpose the data to match the (features, batch_size) format expected by the function\n",
        "    X_train = X_train.T\n",
        "    X_val = X_val.T\n",
        "    X_test = X_test.T\n",
        "    # print(type(X_train))\n",
        "\n",
        "    y_train = y_train.T\n",
        "    y_val = y_val.T\n",
        "    y_test = y_test.T\n",
        "    # Print the number of images in X and y for training, validation, and testing datasets\n",
        "    print(\"Number of images in the training set =\", X_train.shape[1])\n",
        "    print(\"Number of images in the validation set =\", X_val.shape[1])\n",
        "    print(\"Number of images in the test set =\", X_test.shape[1])\n",
        "    print(\"Number of classes =\", num_classes)\n",
        "    print(\"Number of features per example =\", X_train.shape[0])\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
        "\n",
        "# Preprocess the Fashion-MNIST dataset\n",
        "X_train, Y_train, X_val, Y_val, X_test, Y_test = preprocess_fashion_mnist()\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YrwAAhhenIM",
        "outputId": "c4ec6b95-8f64-4f48-ce5b-d28129e0c8cb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images in the training set = 54000\n",
            "Number of images in the validation set = 6000\n",
            "Number of images in the test set = 10000\n",
            "Number of classes = 10\n",
            "Number of features per example = 784\n",
            "(784, 54000)\n",
            "(10, 54000)\n",
            "(784, 10000)\n",
            "(10, 10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPLEMENTATION OF FEEDFORWARD NEURAL NETWORK:<br>\n",
        "It takes the images from the fashion-mnist data as input and outputs a probability distribution over the 10 classes."
      ],
      "metadata": {
        "id": "A092TyAthLMY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ACTIVATION FUNCTION AND DERIVATIVES"
      ],
      "metadata": {
        "id": "xuk6S7P75d9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# index = random.randrange(0,X_train.shape[1])\n",
        "# plt.imshow(X_train[:, index].reshape(28,28), cmap = 'gray')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "-dMHKgD0CxLR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1. / (1.+np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return sigmoid(x) * (1-sigmoid(x))\n",
        "\n",
        "def softmax_derivative(x):\n",
        "    return softmax(x) * (1-softmax(x))\n",
        "\n",
        "def tanh(x):\n",
        "    return np.tanh(x)\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(x, 0)\n",
        "\n",
        "def softmax(x):\n",
        "    expX = np.exp(x)\n",
        "    return expX/np.sum(expX, axis = 0)\n",
        "def derivative_tanh(x):\n",
        "    return (1 - np.power(np.tanh(x), 2))\n",
        "\n",
        "def derivative_relu(x):\n",
        "    return np.array(x>0, dtype = np.float32)"
      ],
      "metadata": {
        "id": "nuDlc044inYt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ok3YQMN1TzNk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializing parameters"
      ],
      "metadata": {
        "id": "kcrPR4DYYs8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# layer_dims = [X.shape[1],100,200,Y.shape[0]]\n",
        "def initialize_parameters(layer_dims):\n",
        "    L = len(layer_dims)\n",
        "    parameters = {}\n",
        "    for l in range(1,L):\n",
        "#         print(L)\n",
        "        parameters[f\"W{l}\"] = np.random.randn(layer_dims[l], layer_dims[l-1])/np.sqrt(layer_dims[l-1])  #the div is to prevent the vanishing gradient prob if the weights initialized at the beginning is too big\n",
        "        parameters[f\"b{l}\"] = np.zeros((layer_dims[l], 1))\n",
        "\n",
        "    return parameters"
      ],
      "metadata": {
        "id": "UOlYfYMtDbUg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_dims = [X_train.shape[0], 100, 200, Y_train.shape[0]]\n",
        "print(layer_dims)\n",
        "params = initialize_parameters(layer_dims)\n",
        "\n",
        "for l in range(1, len(layer_dims)):\n",
        "    print(\"Shape of W\" + str(l) + \":\", params['W' + str(l)].shape)\n",
        "    print(\"Shape of B\" + str(l) + \":\", params['b' + str(l)].shape, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j_AkMBt9De9B",
        "outputId": "09c18341-7744-46ff-a83e-264fceb31013"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[784, 100, 200, 10]\n",
            "Shape of W1: (100, 784)\n",
            "Shape of B1: (100, 1) \n",
            "\n",
            "Shape of W2: (200, 100)\n",
            "Shape of B2: (200, 1) \n",
            "\n",
            "Shape of W3: (10, 200)\n",
            "Shape of B3: (10, 1) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "\n",
        "# # Initialize parameters\n",
        "# def initialize_parameters(layer_sizes, mode='xavier'):\n",
        "#   np.random.seed(42)\n",
        "#   parameters = {}\n",
        "#   for i in range(1, len(layer_sizes)):\n",
        "#     if mode == \"xavier\" :\n",
        "#       parameters[\"W\" + str(i)] = np.random.randn(layer_sizes[i], layer_sizes[i-1])*np.sqrt(2./(layer_sizes[i] + layer_sizes[i-1]))\n",
        "#       parameters[\"b\" + str(i)] = np.zeros((layer_sizes[i],1))\n",
        "#     elif mode == \"random\" :\n",
        "#       parameters[\"W\" + str(i)] = 0.01*np.random.randn(layer_sizes[i], layer_sizes[i-1])\n",
        "#       parameters[\"b\" + str(i)] = 0.01*np.random.randn(layer_sizes[i],1)\n",
        "\n",
        "#   return parameters\n",
        "\n",
        "# def update_init(sizes) :                                  # function to initialize update dictionary that changes the weights and biases\n",
        "#   update = {}\n",
        "#   for i in range(1,len(sizes)):\n",
        "#    update[\"W\"+str(i)] = np.zeros((sizes[i],sizes[i-1]))\n",
        "#    update[\"b\"+str(i)] = np.zeros((sizes[i],1))\n",
        "\n",
        "#   return update\n",
        "\n",
        "# def update_parameters(parameters, gradients, learning_rate):\n",
        "#     L = len(parameters) // 2\n",
        "#     for l in range(1, L + 1):\n",
        "#         parameters[f\"W{l}\"] -= learning_rate * gradients[f\"dW{l}\"]\n",
        "#         parameters[f\"b{l}\"] -= learning_rate * gradients[f\"db{l}\"]\n",
        "\n",
        "#     return parameters\n",
        "\n",
        "# def loss_compute(y,y_hat,parameters,loss_type,reg,sizes):                                               # function to compute the loss/error (both squared error and cross entropy)\n",
        "\n",
        "#   if (loss_type == \"squared_error\"):\n",
        "#     error = np.sum((y-y_hat)**2)/(2*len(y))\n",
        "#   elif (loss_type == \"cross_entropy\") :\n",
        "#     error = -1*np.sum(np.multiply(y,np.log(y_hat)))/len(y)\n",
        "\n",
        "#   reg_error = 0.0                                                                        # account for regularization to avoid overfit of data - L2 norm regularization\n",
        "#   for i in range(1,len(sizes)) :\n",
        "#     reg_error = reg_error + (reg/2)*(np.sum(np.square(parameters[\"W\"+str(i)])))\n",
        "#   error = error + reg_error\n",
        "\n",
        "#   return error\n"
      ],
      "metadata": {
        "id": "5yoc7zDQYsaM"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FEED FORWARD NEURAL NETWORK:"
      ],
      "metadata": {
        "id": "uTYy9bOn6Fjw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Forward Propagation\n"
      ],
      "metadata": {
        "id": "_SR4dPmwnOl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_prop(X, parameters, activation = 'relu'):\n",
        "    forward_cache = {}\n",
        "    L = len(parameters)//2\n",
        "    forward_cache[\"A0\"] = X\n",
        "\n",
        "    for l in range(1, L):\n",
        "        forward_cache[f\"Z{l}\"] = parameters[f\"W{l}\"].dot(forward_cache[f\"A{l-1}\"]) + parameters[f\"b{l}\"]\n",
        "        if activation == 'relu':\n",
        "            forward_cache[f\"A{l}\"] = relu(forward_cache[f\"Z{l}\"])\n",
        "        else:\n",
        "            forward_cache[f\"A{l}\"] = tanh(forward_cache[f\"Z{l}\"])\n",
        "\n",
        "\n",
        "    forward_cache[f\"Z{L}\"] = parameters[f\"W{L}\"].dot(forward_cache[f\"A{L-1}\"]) + parameters[f\"b{L}\"]\n",
        "    if forward_cache[f\"Z{L}\"].shape[0] == 1:\n",
        "        forward_cache[f\"A{L}\"] = sigmoid(forward_cache[f\"Z{L}\"])\n",
        "    else:\n",
        "        forward_cache[f\"A{L}\"] = softmax(forward_cache[f\"Z{L}\"])\n",
        "\n",
        "    return forward_cache[f\"A{L}\"], forward_cache\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# def forward_propagation(X, params, layer_sizes, mode):\n",
        "#     A = {}\n",
        "#     H = {}\n",
        "#     # Z = A, A = H\n",
        "#     L = len(layer_sizes)\n",
        "#     H[0] = X  # Initialize input data as A[0]\n",
        "#     for k in range(1, L):\n",
        "#         W = params[\"W\" + str(k)]\n",
        "#         b = params[\"b\" + str(k)]\n",
        "#         A[k] = b + np.dot(W, H[k - 1])\n",
        "#         if mode == 'sigmoid':\n",
        "#             H[k] = sigmoid(A[k])\n",
        "#         elif mode == 'tanh':\n",
        "#             H[k] = tanh(A[k])\n",
        "#         elif mode == 'relu':\n",
        "#             H[k] = relu(A[k])\n",
        "#     W = params[\"W\" + str(L-1)]\n",
        "#     b = params[\"b\" + str(L-1)]\n",
        "#     A[L-1] = b + np.dot(W, H[L - 2])\n",
        "#     y_hat = softmax(A[L-1])\n",
        "#     return y_hat, H, A\n",
        "\n",
        "\n",
        "# def forward_propagation(X, params, layer_sizes, mode):\n",
        "#     A = {}\n",
        "#     H = {}\n",
        "#     # Z = A, A = H\n",
        "#     L = len(layer_sizes)\n",
        "#     H[0] = X  # Initialize input data as A[0]\n",
        "#     for k in range(1, L):\n",
        "#         W = params[\"W\" + str(k)]\n",
        "#         b = params[\"b\" + str(k)]\n",
        "#         A[k] = b + np.dot(W, H[k - 1])\n",
        "#         if mode == 'sigmoid':\n",
        "#             H[k] = sigmoid(A[k])\n",
        "#         elif mode == 'tanh':\n",
        "#             H[k] = tanh(A[k])\n",
        "#         elif mode == 'relu':\n",
        "#             H[k] = relu(A[k])\n",
        "#     W = params[\"W\" + str(L - 1)]\n",
        "#     b = params[\"b\" + str(L - 1)]\n",
        "#     A[L - 1] = b + np.dot(W, H[L - 2])\n",
        "#     y_hat = softmax(A[L - 1])\n",
        "#     return y_hat, H, A\n",
        "\n",
        "\n",
        "# def forward_propagation(X, params, layer_sizes, mode):\n",
        "#     A = {}\n",
        "#     H = {}\n",
        "#     # Z = A, A = H\n",
        "#     L = len(layer_sizes)\n",
        "#     H[0] = X.reshape(-1, 1)  # Initialize input data as A[0]\n",
        "#     for k in range(1, L):\n",
        "#         W = params[\"W\" + str(k)]\n",
        "#         b = params[\"b\" + str(k)]\n",
        "#         A[k] = b + np.matmul(W, H[k - 1].reshape(-1, 1))\n",
        "#         if mode == 'sigmoid':\n",
        "#             H[k] = sigmoid(A[k])\n",
        "#         elif mode == 'tanh':\n",
        "#             H[k] = tanh(A[k])\n",
        "#         elif mode == 'relu':\n",
        "#             H[k] = relu(A[k])\n",
        "#     W = params[\"W\" + str(L - 1)]\n",
        "#     b = params[\"b\" + str(L - 1)]\n",
        "#     A[L - 1] = b + np.dot(W, H[L - 2].reshape(-1, 1))\n",
        "#     y_hat = softmax(A[L - 1])\n",
        "#     return y_hat, H, A\n",
        "\n",
        "# def forward_propagation(X, params, layer_sizes, mode):\n",
        "#   A = {}\n",
        "#   H = {}\n",
        "\n",
        "#   return y_hat\n",
        "\n"
      ],
      "metadata": {
        "id": "P1UXeHlucZrh"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aL, forw_cache = forward_prop(X_train, params, 'relu')\n",
        "\n",
        "for l in range(len(params)//2 + 1):\n",
        "    print(\"Shape of A\" + str(l) + \" :\", forw_cache['A' + str(l)].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-pMxBS6EkEE",
        "outputId": "958d5484-09e0-4eca-9011-fce6cefbeffd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of A0 : (784, 54000)\n",
            "Shape of A1 : (100, 54000)\n",
            "Shape of A2 : (200, 54000)\n",
            "Shape of A3 : (10, 54000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cost function\n"
      ],
      "metadata": {
        "id": "dtEnMdYVE_lr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_cost(AL, Y, parameters, lambd):\n",
        "    m = Y.shape[1]\n",
        "    L = len(parameters)//2\n",
        "    if Y.shape[0] == 1:\n",
        "        cost = -(1/m) * np.sum(Y*np.log(AL) + (1-Y)*np.log(1 - AL))\n",
        "    else:\n",
        "        cost = -(1/m) * np.sum(Y * np.log(AL))\n",
        "        # reg_sum = 0\n",
        "        # for l in range(1, L):\n",
        "        #   reg_sum+=np.sum(np.square(parameters[f\"W{l}\"]))\n",
        "        # L2_reg_cost = (lambd/(2*m)) * (reg_sum)\n",
        "        # cost+=L2_reg_cost\n",
        "    cost = np.squeeze(cost)\n",
        "\n",
        "    return cost"
      ],
      "metadata": {
        "id": "5lPweVl0EYma"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Backward Propagation"
      ],
      "metadata": {
        "id": "E4BjcA1TnRiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def backward_propagation(AL , Y, parameters,forward_cache, activation):\n",
        "#     grads = {}\n",
        "#     L = len(parameters)//2\n",
        "#     m = AL.shape[1]\n",
        "\n",
        "#     grads[f\"dZ{L}\"] = AL - Y\n",
        "#     grads[f\"dW{L}\"] = (1/m)*np.dot(grads[f\"dZ{L}\"], forward_cache[f\"A{L-1}\"].T)\n",
        "#     grads[f\"db{L}\"] = (1/m)*np.sum(grads[f\"dZ{L}\"], axis =1, keepdims  = True)\n",
        "\n",
        "#     for l in range(L-1, 0 , -1):\n",
        "#         if activation == 'relu':\n",
        "#             grads[f\"dZ{l}\"] = np.dot(parameters[f\"W{l+1}\"].T,grads[f\"dZ{l+1}\"]) * derivative_relu(forward_cache[f'A{l}'])\n",
        "#         else:\n",
        "#             grads[f\"dZ{l}\"] = np.dot(parameters[f\"W{l+1}\"].T,grads[f\"dZ{l+1}\"]) * derivative_tanh(forward_cache[f'A{l}'])\n",
        "\n",
        "#         grads[f\"dW{l}\"] = (1/m)*np.dot(grads[f\"dZ{l}\"], forward_cache[f\"A{l-1}\"].T)\n",
        "#         grads[f\"db{l}\"] = (1/m)*np.sum(grads[f\"dZ{l}\"], axis =1, keepdims  = True)\n",
        "\n",
        "#     return grads\n",
        "\n",
        "\n",
        "def backward_propagation(AL , Y, parameters,forward_cache, activation, lambd = 0.7):\n",
        "    grads = {}\n",
        "    L = len(parameters)//2\n",
        "    m = AL.shape[1]\n",
        "\n",
        "    grads[f\"dZ{L}\"] = AL - Y\n",
        "    grads[f\"dW{L}\"] = (1/m)*np.dot(grads[f\"dZ{L}\"], forward_cache[f\"A{L-1}\"].T) + (lambd*parameters[f\"W{L}\"])/m\n",
        "    grads[f\"db{L}\"] = (1/m)*np.sum(grads[f\"dZ{L}\"], axis =1, keepdims  = True)\n",
        "\n",
        "    for l in range(L-1, 0 , -1):\n",
        "        if activation == 'relu':\n",
        "            grads[f\"dZ{l}\"] = np.dot(parameters[f\"W{l+1}\"].T,grads[f\"dZ{l+1}\"]) * derivative_relu(forward_cache[f'A{l}'])\n",
        "        else:\n",
        "            grads[f\"dZ{l}\"] = np.dot(parameters[f\"W{l+1}\"].T,grads[f\"dZ{l+1}\"]) * derivative_tanh(forward_cache[f'A{l}'])\n",
        "\n",
        "        grads[f\"dW{l}\"] = (1/m)*np.dot(grads[f\"dZ{l}\"], forward_cache[f\"A{l-1}\"].T) + (lambd*parameters[f\"W{l}\"])/m\n",
        "        grads[f\"db{l}\"] = (1/m)*np.sum(grads[f\"dZ{l}\"], axis =1, keepdims  = True)\n",
        "\n",
        "    return grads\n"
      ],
      "metadata": {
        "id": "Nn-VGiSqkmZn"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grads = backward_propagation(forw_cache[\"A\" + str(3)], Y_train, params, forw_cache, 'relu', 0.7)\n",
        "\n",
        "for l in (range(1, len(grads)//3 + 1)):\n",
        "    print(\"Shape of dZ\" + str(l) + \" :\", grads['dZ' + str(l)].shape)\n",
        "    print(\"Shape of dW\" + str(l) + \" :\", grads['dW' + str(l)].shape)\n",
        "    print(\"Shape of dB\" + str(l) + \" :\", grads['db' + str(l)].shape, \"\\n\")\n"
      ],
      "metadata": {
        "id": "B1dj3XuFysXE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "545bb4f6-fbf0-4803-82b7-d1632c05a51f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of dZ1 : (100, 54000)\n",
            "Shape of dW1 : (100, 784)\n",
            "Shape of dB1 : (100, 1) \n",
            "\n",
            "Shape of dZ2 : (200, 54000)\n",
            "Shape of dW2 : (200, 100)\n",
            "Shape of dB2 : (200, 1) \n",
            "\n",
            "Shape of dZ3 : (10, 54000)\n",
            "Shape of dW3 : (10, 200)\n",
            "Shape of dB3 : (10, 1) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = random.randrange(0,X_train.shape[1])\n",
        "plt.imshow(X_train[:, index].reshape(28,28), cmap = 'gray')\n",
        "plt.show()\n",
        "# # Define the neural network architecture\n",
        "\n",
        "# # Input layer (784 features), 2 hidden layers (128 and 64 neurons), Output layer (10 classes)\n",
        "layer_sizes = [784, 128,32,64,10]\n",
        "# parameters, train_loss_history = train(X_train, y_train, layer_sizes, mode='xavier', activation='relu', loss_type='cross_entropy', num_epochs=5, learning_rate=0.1)\n",
        "\n",
        "# # Make predictions on the test set\n",
        "# y_pred = predict(X_test, parameters, layer_sizes,activation='relu')\n",
        "\n",
        "# # Calculate accuracy on the test set\n",
        "# accuracy = np.mean(np.argmax(y_pred, axis=0) == np.argmax(y_test, axis=1))\n",
        "# print(\"Test Accuracy:\", accuracy)\n",
        "\n"
      ],
      "metadata": {
        "id": "upBhibVhzCTL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "outputId": "78542e5c-4f19-4a1c-d018-c8ec6e0aa584"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def update_parameters(parameters, grads, learning_rate):\n",
        "\n",
        "    L = len(parameters) // 2\n",
        "    for l in range(1, L):\n",
        "        parameters[f\"W{l}\"] = parameters[f\"W{l}\"] - learning_rate*grads[f'dW{l}']\n",
        "        parameters[f\"b{l}\"] = parameters[f\"b{l}\"] - learning_rate*grads[f'db{l}']\n",
        "    return parameters"
      ],
      "metadata": {
        "id": "de5P2AilGwwV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grad_desc(X, Y, layer_dims, learning_rate, activation = 'relu', n_epoch = 100, lambd = 0.7):\n",
        "\n",
        "    parameters = initialize_parameters(layer_dims)\n",
        "\n",
        "    for i in range(n_epoch):\n",
        "\n",
        "        AL , forward_cache  = forward_prop(X, parameters, activation)\n",
        "\n",
        "        cost = compute_cost(AL, Y, parameters, lambd)\n",
        "\n",
        "        grads = backward_propagation(AL , Y, parameters,forward_cache, activation)\n",
        "\n",
        "        parameters = update_parameters(parameters, grads, learning_rate)\n",
        "\n",
        "        if i % (n_epoch/10) == 0:\n",
        "            print(\"\\niter:{} \\t cost: {} \\t train_acc:{} \\t test_acc:{}\".format(i, np.round(cost, 2), predict(X_train, Y_train, parameters, activation), predict(X_test, Y_test, parameters, activation)))\n",
        "        if i % 10 == 0:\n",
        "            print(\"==\", end = '')\n",
        "\n",
        "    return parameters"
      ],
      "metadata": {
        "id": "UghSuSBCG0wS"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, y, parameters, activation):\n",
        "\n",
        "    m = X.shape[1]\n",
        "    y_pred, caches = forward_prop(X, parameters, activation)\n",
        "\n",
        "    if y.shape[0] == 1:\n",
        "        y_pred = np.array(y_pred > 0.5, dtype = 'float')\n",
        "    else:\n",
        "        y = np.argmax(y, 0)\n",
        "        y_pred = np.argmax(y_pred, 0)\n",
        "\n",
        "    return np.round(np.sum((y_pred == y)/m), 2)*100"
      ],
      "metadata": {
        "id": "ynRmybAtm2hz"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "layer_dims = [X_train.shape[0], 20,10, Y_train.shape[0]]\n",
        "lr = 0.005\n",
        "n_epoch = 1000\n",
        "activation = 'tanh'\n",
        "\n",
        "\n",
        "parameters = grad_desc(X_train, Y_train, layer_dims, lr, activation = activation, n_epoch = n_epoch, lambd = 0.7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxVRC5fIG3qv",
        "outputId": "2d117445-8836-4488-af0e-00a14a3f1ad8"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "iter:0 \t cost: 2.37 \t train_acc:11.0 \t test_acc:11.0\n",
            "====================\n",
            "iter:100 \t cost: 1.97 \t train_acc:32.0 \t test_acc:32.0\n",
            "====================\n",
            "iter:200 \t cost: 1.82 \t train_acc:42.0 \t test_acc:41.0\n",
            "====================\n",
            "iter:300 \t cost: 1.73 \t train_acc:48.0 \t test_acc:47.0\n",
            "====================\n",
            "iter:400 \t cost: 1.67 \t train_acc:54.0 \t test_acc:52.0\n",
            "====================\n",
            "iter:500 \t cost: 1.61 \t train_acc:60.0 \t test_acc:59.0\n",
            "====================\n",
            "iter:600 \t cost: 1.57 \t train_acc:63.0 \t test_acc:62.0\n",
            "====================\n",
            "iter:700 \t cost: 1.54 \t train_acc:65.0 \t test_acc:64.0\n",
            "====================\n",
            "iter:800 \t cost: 1.51 \t train_acc:66.0 \t test_acc:64.0\n",
            "====================\n",
            "iter:900 \t cost: 1.48 \t train_acc:66.0 \t test_acc:65.0\n",
            "===================="
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def update_params_momentum(parameters, grads, learning_rate, beta, prev_updates):\n",
        "  L = len(parameters) // 2\n",
        "  for l in range(1, L):\n",
        "    prev_updates[f\"W{l}\"] = beta*\n",
        "    parameters[f\"W{l}\"] = parameters[f\"W{l}\"] - learning_rate*grads[f'dW{l}']\n",
        "    parameters[f\"b{l}\"] = parameters[f\"b{l}\"] - learning_rate*grads[f'db{l}']\n",
        "  return parameters\n",
        "def update_parameters_sgd(parameters, grads, learning_rate):\n",
        "  pass\n",
        "\n",
        "\n",
        ""
      ],
      "metadata": {
        "id": "QrgDNzurn6Zg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " def val_loss(y,y_hat,loss_type):                                # function to compute the loss/error (both squared error and cross entropy)\n",
        "  l = 0\n",
        "  if (loss_type == \"squared_error\"):\n",
        "\n",
        "    l = np.sum((y-y_hat)**2)/(2*len(y))\n",
        "  elif (loss_type == \"cross_entropy\") :\n",
        "    l = -1*np.sum(np.multiply(y,np.log(y_hat)))/len(y)\n",
        "  return l\n",
        "\n",
        "def calcAccLoss(parameters, xArr, yArr, sizes, loss_type, activation, y_hat ,type=\"val\", regu=None):\n",
        "    acc = 0.0\n",
        "    lossVal = 0.0\n",
        "    for x, y in zip(xArr, yArr):\n",
        "        # print(y_hat)\n",
        "        if y_hat.argmax() == y.argmax():\n",
        "            acc += 1\n",
        "        if type == \"val\":\n",
        "            lossVal += val_loss(y, y_hat.reshape(-1, 1), loss_type)\n",
        "        elif type == \"trng\":\n",
        "            lossVal += loss_compute(y, y_hat.reshape(-1, 1), parameters, loss_type, regu, sizes)\n",
        "    acc = acc / len(xArr)\n",
        "    return (acc, lossVal)"
      ],
      "metadata": {
        "id": "WEL2DEuBAQmx"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_parameters_momentum(parameters, grads, learning_rate, beta, previous_updates):\n",
        "    ''' Update W and b of the NN according to momentum updates\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    parameters: dict\n",
        "        contains weights and biases of the NN\n",
        "\n",
        "    grads: dict\n",
        "        contains gradients wrt W and b returned by backpropagation\n",
        "\n",
        "    learning_rate: float\n",
        "        learning rate\n",
        "\n",
        "    beta: float\n",
        "        decay rate\n",
        "\n",
        "    previous_updates: dict\n",
        "        contains previous W and b values, accumulated in a weighted fashion along with the gradients eg.\n",
        "        previous_updates[Wi] = beta*previous_updates[Wi] + (1-beta)*gradient[dWi]\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    parameters: dict\n",
        "        updated NN parameters\n",
        "\n",
        "    previous updates: dict\n",
        "        updated previous updates\n",
        "\n",
        "    '''\n",
        "    L = len(parameters) // 2 # number of layers in the neural network\n",
        "\n",
        "    for l in range(1, L + 1):\n",
        "        previous_updates[\"W\"+str(l)] = beta*previous_updates[\"W\"+str(l)] + (1-beta)*grads[\"dW\" + str(l)]\n",
        "        parameters[\"W\" + str(l)] = parameters[\"W\" + str(l)] - learning_rate*previous_updates[\"W\"+str(l)]\n",
        "\n",
        "        previous_updates[\"b\"+str(l)] = beta*previous_updates[\"b\"+str(l)] + (1-beta)*grads[\"db\" + str(l)]\n",
        "        parameters[\"b\" + str(l)] = parameters[\"b\" + str(l)] - learning_rate*previous_updates[\"b\"+str(l)]\n",
        "\n",
        "    return parameters, previous_updates"
      ],
      "metadata": {
        "id": "4fahniLK2o2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimized GD's"
      ],
      "metadata": {
        "id": "POvRJevPMy6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Momentum GD\n",
        "\n",
        "def update_init(sizes) :                                  # function to initialize update dictionary that changes the weights and biases\n",
        "  update = {}\n",
        "  for i in range(1,len(sizes)):\n",
        "   update[\"W\"+str(i)] = np.zeros((sizes[i],sizes[i-1]))\n",
        "   update[\"b\"+str(i)] = np.zeros((sizes[i],1))\n",
        "  return update\n",
        "\n",
        "def grad_init(sizes):\n",
        "  grads={}\n",
        "  layers=len(sizes)\n",
        "  for i in range(1,layers):\n",
        "    grads[\"dW\" + str(i)] = np.zeros((sizes[i], sizes[i-1]))\n",
        "    grads[\"db\" + str(i)] = np.zeros((sizes[i],1))\n",
        "  return grads\n",
        "\n",
        "def momentum_GD(X, Y, layer_sizes, mode='xavier', activation='relu', loss_type='cross_entropy', num_epochs=5, lr=0.1, mini_batch=1, reg=1):\n",
        "    steps = 0\n",
        "    parameters = initialize_parameters(layer_sizes, mode)\n",
        "    train_loss_history = []\n",
        "    gamma = 0.9\n",
        "    update = update_init(layer_sizes)\n",
        "    for epoch in range(num_epochs):\n",
        "        for j in range(0, X.shape[1], mini_batch):\n",
        "            X_mini = X[:, j:j + mini_batch]\n",
        "            Y_mini = Y[:, j:j + mini_batch]\n",
        "            if Y_mini.size:\n",
        "                grads = grad_init(layer_sizes)\n",
        "\n",
        "                for col in range(X_mini.shape[1]):\n",
        "                    x = X_mini[:, col].reshape(-1, 1)\n",
        "                    y = Y_mini[:, col].reshape(-1, 1)\n",
        "                    y_hat, H, A = forward_prop(x, parameters, layer_sizes, activation)\n",
        "                    gradients = backward_propagation(x, y, H, A, y_hat, parameters, layer_sizes, activation, loss_type)\n",
        "\n",
        "                    for i in range(1, len(layer_sizes)-1):\n",
        "                        grads[\"dW\" + str(i)] += gradients[\"dW\" + str(i)]\n",
        "                        grads[\"db\" + str(i)] += gradients[\"db\" + str(i)]\n",
        "\n",
        "            for i in range(1, len(layer_sizes)):\n",
        "                grads[\"dW\" + str(i)] /= mini_batch\n",
        "                grads[\"db\" + str(i)] /= mini_batch\n",
        "                update[\"W\" + str(i)] = gamma * update[\"W\" + str(i)] + lr * grads[\"dW\" + str(i)]\n",
        "                update[\"b\" + str(i)] = gamma * update[\"b\" + str(i)] + lr * grads[\"db\" + str(i)]\n",
        "                parameters[\"W\" + str(i)] = (1 - lr * reg) * parameters[\"W\" + str(i)] - update[\"W\" + str(i)]\n",
        "                parameters[\"b\" + str(i)] = (1 - lr * reg) * parameters[\"b\" + str(i)] - update[\"b\" + str(i)]\n",
        "\n",
        "            steps = steps + 1\n",
        "            if steps == 10000:\n",
        "                acc, lossTot = calcAccLoss(parameters, X, Y, layer_sizes, loss_type, activation, y_hat, type=\"trng\", regu=reg)\n",
        "                accVal, lossTotVal = calcAccLoss(parameters, X_val, Y_val, layer_sizes, loss_type, activation, y_hat)\n",
        "                print( {\"Accuracy\": acc, \"Loss\": lossTot, \"Accuracy_val\": accVal, \"Loss_val\": lossTotVal, \"Epoch\": epoch})\n",
        "                steps = 0\n",
        "\n",
        "    return parameters\n",
        "par = momentum_GD(X_train, Y_train, layer_sizes, \"xavier\", \"sigmoid\", \"cross_entropy\", 5, 0.1, 2, 15)\n",
        "print(par)"
      ],
      "metadata": {
        "id": "zFb_tlSFMyn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# from tensorflow.keras.datasets import fashion_mnist\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# def preprocess_fashion_mnist():\n",
        "#     # Load the Fashion-MNIST dataset\n",
        "#     (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "#     # Flatten and normalize the input data\n",
        "#     X_train = X_train.reshape(-1, 28*28)  # Flatten each image to a 1D vector\n",
        "#     X_test = X_test.reshape(-1, 28*28)\n",
        "#     X_train = X_train.astype('float32') / 255.0  # Normalize pixel values to [0, 1]\n",
        "#     X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "#     # One-hot encode the labels\n",
        "#     num_classes = 10\n",
        "#     y_train = np.eye(num_classes)[y_train]  # One-hot encode the training labels\n",
        "#     y_test = np.eye(num_classes)[y_test]    # One-hot encode the test labels\n",
        "\n",
        "#     # Split the data into training, validation, and test sets\n",
        "#     X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=6000, random_state=42)\n",
        "\n",
        "#     # Transpose the data to match the (features, batch_size) format expected by the function\n",
        "#     X_train = X_train.T\n",
        "#     X_val = X_val.T\n",
        "#     X_test = X_test.T\n",
        "\n",
        "#     # Print the number of images in X and y for training, validation, and testing datasets\n",
        "#     print(\"Number of images in the training set =\", X_train.shape[1])\n",
        "#     print(\"Number of images in the validation set =\", X_val.shape[1])\n",
        "#     print(\"Number of images in the test set =\", X_test.shape[1])\n",
        "#     print(\"Number of classes =\", num_classes)\n",
        "#     print(\"Number of features per example =\", X_train.shape[0])\n",
        "\n",
        "#     return X_train, y_train, X_val, y_val, X_test, y_test\n",
        "\n",
        "# # Preprocess the Fashion-MNIST dataset\n",
        "# X_train, Y_train, X_val, Y_val, X_test, y_test = preprocess_fashion_mnist()\n",
        "\n",
        "# def sigmoid(x):\n",
        "#     return 1. / (1. + np.exp(-x))\n",
        "\n",
        "# def sigmoid_derivative(x):\n",
        "#     return sigmoid(x) * (1 - sigmoid(x))\n",
        "\n",
        "# def relu(x):\n",
        "#     return np.maximum(0, x)\n",
        "\n",
        "# def relu_derivative(x):\n",
        "#     return 1 * (x > 0)\n",
        "\n",
        "# def tanh(x):\n",
        "#     return np.tanh(x)\n",
        "\n",
        "# def tanh_derivative(x):\n",
        "#     return 1 - (np.tanh(x) ** 2)\n",
        "\n",
        "# def softmax(x):\n",
        "#     return np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "\n",
        "# def softmax_derivative(x):\n",
        "#     return softmax(x) * (1 - softmax(x))\n",
        "\n",
        "# def initialize_parameters(layer_sizes, mode='xavier'):\n",
        "#     np.random.seed(42)\n",
        "#     parameters = {}\n",
        "#     for i in range(1, len(layer_sizes)):\n",
        "#         if mode == \"xavier\":\n",
        "#             parameters[\"W\" + str(i)] = np.random.randn(layer_sizes[i], layer_sizes[i-1]) * np.sqrt(2. / (layer_sizes[i] + layer_sizes[i-1]))\n",
        "#             parameters[\"b\" + str(i)] = np.zeros((layer_sizes[i], 1))\n",
        "#         elif mode == \"random\":\n",
        "#             parameters[\"W\" + str(i)] = 0.01 * np.random.randn(layer_sizes[i], layer_sizes[i-1])\n",
        "#             parameters[\"b\" + str(i)] = 0.01 * np.random.randn(layer_sizes[i], 1)\n",
        "#     return parameters\n",
        "\n",
        "# def update_init(sizes):\n",
        "#     update = {}\n",
        "#     for i in range(1, len(sizes)):\n",
        "#         update[\"W\" + str(i)] = np.zeros((sizes[i], sizes[i-1]))\n",
        "#         update[\"b\" + str(i)] = np.zeros((sizes[i], 1))\n",
        "#     return update\n",
        "\n",
        "# def update_parameters(parameters, gradients, learning_rate):\n",
        "#     L = len(parameters) // 2\n",
        "#     for l in range(1, L + 1):\n",
        "#         parameters[f\"W{l}\"] -= learning_rate * gradients[f\"dW{l}\"]\n",
        "#         parameters[f\"b{l}\"] -= learning_rate * gradients[f\"db{l}\"]\n",
        "#     return parameters\n",
        "\n",
        "# def loss_compute(y, y_hat, parameters, loss_type, reg, sizes):\n",
        "#     if loss_type == \"cross_entropy\":\n",
        "#         error = -1 * np.sum(np.multiply(y, np.log(y_hat))) / len(y)\n",
        "#     reg_error = 0.0\n",
        "#     for i in range(1, len(sizes)):\n",
        "#         reg_error = reg_error + (reg / 2) * (np.sum(np.square(parameters[\"W\" + str(i)])))\n",
        "#     error = error + reg_error\n",
        "#     return error\n",
        "\n",
        "# def forward_propagation(X, params, layer_sizes, mode):\n",
        "#     A = {}\n",
        "#     H = {}\n",
        "#     L = len(layer_sizes)\n",
        "#     H[0] = X.reshape(-1, 1)\n",
        "#     for k in range(1, L):\n",
        "#         W = params[\"W\" + str(k)]\n",
        "#         b = params[\"b\" + str(k)]\n",
        "#         A[k] = b + np.dot(W, H[k - 1].reshape(-1, 1))\n",
        "#         if mode == 'sigmoid':\n",
        "#             H[k] = sigmoid(A[k])\n",
        "#         elif mode == 'tanh':\n",
        "#             H[k] = tanh(A[k])\n",
        "#         elif mode == 'relu':\n",
        "#             H[k] = relu(A[k])\n",
        "#     W = params[\"W\" + str(L - 1)]\n",
        "#     b = params[\"b\" + str(L - 1)]\n",
        "#     A[L - 1] = b + np.dot(W, H[L - 2].reshape(-1, 1))\n",
        "#     y_hat = softmax(A[L - 1])\n",
        "#     return y_hat, H, A\n",
        "\n",
        "# def derivative(x, mode):\n",
        "#     if mode == 'sigmoid':\n",
        "#         return sigmoid_derivative(x)\n",
        "#     elif mode == 'tanh':\n",
        "#         return tanh_derivative(x)\n",
        "#     elif mode == 'relu':\n",
        "#         return relu_derivative(x)\n",
        "#     return None\n",
        "\n",
        "# def backward_propagation(X, Y, H, A, y_hat, params, layer_sizes, mode, loss_type):\n",
        "#     L = len(layer_sizes)\n",
        "#     gradients = {}\n",
        "#     y_hat = y_hat.T\n",
        "\n",
        "#     if loss_type == \"cross_entropy\":\n",
        "#         gradients[f\"dH{L - 1}\"] = -(Y / y_hat)\n",
        "#         gradients[f\"dA{L - 1}\"] = -(Y - y_hat)\n",
        "#     for i in range(1, L):\n",
        "#         gradients[f\"dW{i}\"] = np.zeros((layer_sizes[i], layer_sizes[i - 1]))\n",
        "#         gradients[f\"db{i}\"] = np.zeros((layer_sizes[i], 1))\n",
        "#         gradients[f\"dA{i}\"] = np.zeros((layer_sizes[i], 1))\n",
        "#         gradients[f\"dH{i}\"] = np.zeros((layer_sizes[i], 1))\n",
        "\n",
        "#     for k in range(L - 1, 0, -1):\n",
        "#         gradients[f\"dW{k}\"] = np.matmul(gradients[f\"dA{k}\"], np.transpose(H[k - 1]))\n",
        "#         gradients[f\"db{k}\"] = gradients[f\"dA{k}\"]\n",
        "\n",
        "#         if k > 1:\n",
        "#             gradients[f\"dH{k - 1}\"] = np.dot(np.transpose(params[f\"W{k}\"]), gradients[f\"dA{k}\"])\n",
        "#             gradients[f\"dA{k - 1}\"] = np.multiply(gradients[f\"dH{k-1}\"], derivative(A[k - 1], mode))\n",
        "\n",
        "#     return gradients\n",
        "\n",
        "# def val_loss(y, y_hat, loss_type):\n",
        "#     l = 0\n",
        "#     if loss_type == \"squared_error\":\n",
        "#         l = np.sum((y - y_hat) ** 2) / (2 * len(y))\n",
        "#     elif loss_type == \"cross_entropy\":\n",
        "#         l = -1 * np.sum(np.multiply(y, np.log(y_hat))) / len(y)\n",
        "#     return l\n",
        "\n",
        "# def calcAccLoss(parameters, xArr, yArr, sizes, loss_type, activation, y_hat, type=\"val\", regu=None):\n",
        "#     acc = 0.0\n",
        "#     lossVal = 0.0\n",
        "#     for x, y in zip(xArr, yArr):\n",
        "#         if y_hat.argmax() == y.argmax():\n",
        "#             acc += 1\n",
        "#         if type == \"val\":\n",
        "#             lossVal += val_loss(y, y_hat.reshape(-1, 1), loss_type)\n",
        "#         elif type == \"trng\":\n",
        "#             lossVal += loss_compute(y, y_hat.reshape(-1, 1), parameters, loss_type, regu, sizes)\n",
        "#     acc = acc / len(xArr)\n",
        "#     return acc, lossVal\n",
        "\n",
        "# def momentum_GD(X, Y, layer_sizes, mode='xavier', activation='relu', loss_type='cross_entropy', num_epochs=5, lr=0.1, mini_batch=1, reg=1):\n",
        "#     steps = 0\n",
        "#     parameters = initialize_parameters(layer_sizes, mode)\n",
        "#     train_loss_history = []\n",
        "#     gamma = 0.9\n",
        "#     update = update_init(layer_sizes)\n",
        "#     for epoch in range(num_epochs):\n",
        "\n",
        "#         for j in range(0, X.shape[1], mini_batch):\n",
        "#             X_mini = X[:, j:j + mini_batch]\n",
        "#             Y_mini = Y[:, j:j + mini_batch]\n",
        "#             if Y_mini.size:\n",
        "#                 grads = grad_init(layer_sizes)\n",
        "\n",
        "#                 for col in range(X_mini.shape[1]):\n",
        "#                     x = X_mini[:, col].reshape(-1, 1)\n",
        "#                     y = Y_mini[:, col].reshape(-1, 1)\n",
        "#                     y_hat, H, A = forward_propagation(x, parameters, layer_sizes, activation)\n",
        "#                     gradients = backward_propagation(x, y, H, A, y_hat, parameters, layer_sizes, activation, loss_type)\n",
        "\n",
        "#                     for i in range(1, len(layer_sizes)-1):\n",
        "#                         grads[\"dW\" + str(i)] += gradients[\"dW\" + str(i)]\n",
        "#                         grads[\"db\" + str(i)] += gradients[\"db\" + str(i)]\n",
        "\n",
        "\n",
        "\n",
        "#             for i in range(1, len(layer_sizes)):\n",
        "#                 grads[\"dW\" + str(i)] /= mini_batch\n",
        "#                 grads[\"db\" + str(i)] /= mini_batch\n",
        "#                 update[\"W\" + str(i)] = gamma * update[\"W\" + str(i)] + lr * grads[\"dW\" + str(i)]\n",
        "#                 update[\"b\" + str(i)] = gamma * update[\"b\" + str(i)] + lr * grads[\"db\" + str(i)]\n",
        "#                 parameters[\"W\" + str(i)] = (1 - lr * reg) * parameters[\"W\" + str(i)] - update[\"W\" + str(i)]\n",
        "#                 parameters[\"b\" + str(i)] = (1 - lr * reg) * parameters[\"b\" + str(i)] - update[\"b\" + str(i)]\n",
        "\n",
        "#             steps = steps + 1\n",
        "#             if steps == 10000:\n",
        "#                 acc, lossTot = calcAccLoss(parameters, X_train, Y_train, layer_sizes, loss_type, activation, y_hat, type=\"trng\", regu=reg)\n",
        "#                 accVal, lossTotVal = calcAccLoss(parameters, X_val, Y_val, layer_sizes, loss_type, activation, y_hat=y_hat)\n",
        "#                 print({\"Accuracy\": acc, \"Loss\": lossTot, \"Accuracy_val\": accVal, \"Loss_val\": lossTotVal, \"Epoch\": epoch})\n",
        "#                 steps = 0\n",
        "\n",
        "#     return parameters\n",
        "\n",
        "# # Modify the layer_sizes and other parameters as needed\n",
        "# layer_sizes = [X_train.shape[0], 128, 64, 10]  # Input layer, 2 hidden layers, output layer\n",
        "# par = momentum_GD(X_train, Y_train, layer_sizes, mode=\"xavier\", activation=\"relu\", loss_type=\"cross_entropy\", num_epochs=20, lr=0.01, mini_batch=5, reg=0.01)\n"
      ],
      "metadata": {
        "id": "ehXX4x4qicin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the neural network on the test data\n",
        "acc, loss = calcAccLoss(par, X_test, y_test, layer_sizes, \"cross_entropy\",\"relu\", 2 )\n",
        "\n",
        "# Print the accuracy\n",
        "print(\"Accuracy:\", acc)"
      ],
      "metadata": {
        "id": "kofbjjKeIeO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Nesterov acceleracted GD\n",
        "def nesterov_accelerated_GD(X, Y, layer_sizes, mode='xavier', activation='relu', loss_type='cross_entropy', num_epochs=100, lr=0.1, mini_batch=1, reg=2, log= False):\n",
        "  steps = 0\n",
        "  parameters = initialize_parameters(layer_sizes, mode)\n",
        "  train_loss_history = []\n",
        "  gamma = 0.9\n",
        "  update = update_init(layer_sizes)\n",
        "  for n in range(num_epochs):\n",
        "\n",
        "    for j in range(0, X_train.shape[0], mini_batch):\n",
        "      X_mini = X[:, j:j + mini_batch]\n",
        "      Y_mini = Y[:, j:j + mini_batch]\n",
        "      # if Y_mini.size:\n",
        "      grads = grad_init(layer_sizes)\n",
        "      for i in range(1,len(layer_sizes)):                                                       #perform update before back propogation\n",
        "        update[\"W\"+str(i)] = gamma*update[\"W\"+str(i)]\n",
        "        update[\"b\"+str(i)] = gamma*update[\"b\"+str(i)]\n",
        "        parameters[\"W\"+str(i)] = (1-lr*reg)*parameters[\"W\"+str(i)] - update[\"W\"+str(i)]\n",
        "        parameters[\"b\"+str(i)] = (1-lr*reg)*parameters[\"b\"+str(i)] - update[\"b\"+str(i)]\n",
        "\n",
        "      for x,y in zip(X_mini,Y_mini):\n",
        "        y_hat, H, A = forward_propagation(x, parameters, layer_sizes, activation)\n",
        "        # H =\n",
        "        gradients = backward_propagation(x, y, H, A, y_hat, parameters, layer_sizes, activation, loss_type)\n",
        "\n",
        "      for k in range(1,len(layer_sizes)) :\n",
        "        update[\"W\"+str(k)] = gamma*update[\"W\"+str(k)] + lr*grads[\"dW\"+str(k)]\n",
        "        update[\"b\"+str(k)] = gamma*update[\"b\"+str(k)] + lr*grads[\"db\"+str(k)]\n",
        "        parameters[\"W\"+str(k)] = (1-lr*reg)*parameters[\"W\"+str(k)] - update[\"W\"+str(k)]\n",
        "        parameters[\"b\"+str(k)] = (1-lr*reg)*parameters[\"b\"+str(k)] - update[\"b\"+str(k)]\n",
        "      steps=steps+1\n",
        "      if steps==10000:\n",
        "        if log:\n",
        "          acc,lossTot=calcAccLoss(parameters,X_train,Y_train,layer_sizes,loss_type,activation,type=\"trng\",regu=reg)\n",
        "          accVal,lossTotVal=calcAccLoss(parameters,X_val,Y_val,layer_sizes,loss_type,activation)\n",
        "\n",
        "          wandb.log({\"Accuracy\":acc,\"Loss\":lossTot,\"Accuracy_val\":accVal,\"Loss_val\":lossTotVal,\"Epoch\":n,\"n_datatrain\":j + minibatch_size+n*54000})\n",
        "        steps=0\n",
        "\n",
        "  return parameters\n",
        "\n",
        "\n",
        "par = nesterov_accelerated_GD(X_train, Y_train, layer_sizes, \"xavier\", \"relu\", \"cross_entropy\", 5, 0.1, 1, 2, False)\n",
        "print(par)\n"
      ],
      "metadata": {
        "id": "SNMwXaeHsLk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HEK6lzfKIcoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FALSE\n",
        "\n",
        "\n",
        "#stochastic GD\n",
        "def stochastic_GD(X_train,Y_train,activation,n_epoch,sizes,lr,reg,w_init,loss_type,minibatch_size=1,log=False) :\n",
        "\n",
        "  steps=0\n",
        "  parameters = network_init(sizes,w_init)\n",
        "  update = update_init(sizes)\n",
        "  gamma = 0.9\n",
        "  for n in range(n_epoch):\n",
        "\n",
        "    for j in range(0, X_train.shape[0], minibatch_size):                                        #minibatch division\n",
        "      X_mini = X_train[j:j + minibatch_size]\n",
        "      Y_mini = Y_train[j:j + minibatch_size]\n",
        "\n",
        "      grads = grad_init(sizes)\n",
        "      for x,y in zip(X_mini,Y_mini):\n",
        "        y_hat,A,H = feed_forward(x,parameters,sizes,activation)\n",
        "        grads = back_prop(x,y,y_hat,grads,A,H,parameters,sizes,loss_type,activation,reg)\n",
        "\n",
        "      for i in range(1,len(sizes)-1) :                                                          #updating the parameters\n",
        "        parameters[\"W\"+str(i)] = (1-lr*reg)*parameters[\"W\"+str(i)] - lr*grads[\"dW\"+str(i)]\n",
        "        parameters[\"b\"+str(i)] = (1-lr*reg)*parameters[\"b\"+str(i)] - lr*grads[\"db\"+str(i)]\n",
        "      steps=steps+1\n",
        "      if steps==10000:\n",
        "        if log:\n",
        "          acc,lossTot=calcAccLoss(parameters,X_train,Y_train,sizes,loss_type,activation,type=\"trng\",regu=reg)\n",
        "          accVal,lossTotVal=calcAccLoss(parameters,X_val,Y_val,sizes,loss_type,activation)\n",
        "\n",
        "          wandb.log({\"Accuracy\":acc,\"Loss\":lossTot,\"Accuracy_val\":accVal,\"Loss_val\":lossTotVal,\"Epoch\":n,\"n_datatrain\":j + minibatch_size+n*54000})\n",
        "        steps=0\n",
        "\n",
        "  return parameters\n",
        "\n",
        "#rmsprop GD\n",
        "def rmsprop_GD(X_train,Y_train,activation,n_epoch,sizes,lr,reg,w_init,loss_type,minibatch_size=1,log=False) :\n",
        "\n",
        "  steps=0\n",
        "  parameters = network_init(sizes,w_init)\n",
        "  update = update_init(sizes)\n",
        "  v = update_init(sizes)\n",
        "\n",
        "  betal = 0.99 #check this\n",
        "  eps = 1e-8\n",
        "\n",
        "  for n in range(n_epoch):\n",
        "\n",
        "    for j in range(0, X_train.shape[0], minibatch_size):\n",
        "      X_mini = X_train[j:j + minibatch_size]\n",
        "      Y_mini = Y_train[j:j + minibatch_size]\n",
        "\n",
        "      grads = grad_init(sizes)\n",
        "      for x,y in zip(X_mini,Y_mini):\n",
        "        y_hat,A,H = feed_forward(x,parameters,sizes,activation)\n",
        "        grads = back_prop(x,y,y_hat,grads,A,H,parameters,sizes,loss_type,activation,reg)\n",
        "\n",
        "      for i in range(1,len(sizes)-1) :                                                                   #updating the parameters\n",
        "        v[\"W\"+str(i)] = betal*v[\"W\"+str(i)] + (1-betal)*grads[\"dW\"+str(i)]**2                            #v_w update\n",
        "        v[\"b\"+str(i)] = betal*v[\"b\"+str(i)] + (1-betal)*grads[\"db\"+str(i)]**2                            #v_b update\n",
        "\n",
        "        update[\"W\"+str(i)]=lr*np.multiply(np.reciprocal(np.sqrt(v[\"W\"+str(i)]+eps)),grads[\"dW\"+str(i)])\n",
        "        update[\"b\"+str(i)]=lr*np.multiply(np.reciprocal(np.sqrt(v[\"b\"+str(i)]+eps)),grads[\"db\"+str(i)])\n",
        "\n",
        "        parameters[\"W\"+str(i)] = (1-lr*reg)*parameters[\"W\"+str(i)] - update[\"W\"+str(i)]\n",
        "        parameters[\"b\"+str(i)] = (1-lr*reg)*parameters[\"b\"+str(i)] - update[\"b\"+str(i)]\n",
        "      steps=steps+1\n",
        "      if steps==10000:\n",
        "        if log:\n",
        "          acc,lossTot=calcAccLoss(parameters,X_train,Y_train,sizes,loss_type,activation,type=\"trng\",regu=reg)\n",
        "          accVal,lossTotVal=calcAccLoss(parameters,X_val,Y_val,sizes,loss_type,activation)\n",
        "\n",
        "          wandb.log({\"Accuracy\":acc,\"Loss\":lossTot,\"Accuracy_val\":accVal,\"Loss_val\":lossTotVal,\"Epoch\":n,\"n_datatrain\":j + minibatch_size+n*54000})\n",
        "        steps=0\n",
        "\n",
        "  return parameters\n",
        "\n",
        "#Adam GD\n",
        "def adam_GD(X_train,Y_train,activation,n_epoch,sizes,lr,reg,w_init,loss_type,minibatch_size=1,log=False) :\n",
        "  steps=0\n",
        "  parameters = network_init(sizes,w_init)\n",
        "  update = update_init(sizes)\n",
        "  m = update_init(sizes)\n",
        "  v = update_init(sizes)\n",
        "\n",
        "  beta1 = 0.9\n",
        "  beta2 = 0.999\n",
        "  eps = 1e-8\n",
        "  for n in range(n_epoch):\n",
        "\n",
        "    for j in range(0, X_train.shape[0], minibatch_size):\n",
        "      X_mini = X_train[j:j + minibatch_size]\n",
        "      Y_mini = Y_train[j:j + minibatch_size]\n",
        "\n",
        "      grads = grad_init(sizes)\n",
        "      for x,y in zip(X_mini,Y_mini):\n",
        "        y_hat,A,H = feed_forward(x,parameters,sizes,activation)\n",
        "        grads = back_prop(x,y,y_hat,grads,A,H,parameters,sizes,loss_type,activation,reg)\n",
        "\n",
        "      for i in range(1,len(sizes)-1) :                                                    #updating the parameters\n",
        "        m[\"W\"+str(i)] = beta1*m[\"W\"+str(i)] + (1-beta1)*grads[\"dW\"+str(i)]                #m_w update\n",
        "        m[\"b\"+str(i)] = beta1*m[\"b\"+str(i)] + (1-beta1)*grads[\"db\"+str(i)]                #m_b update\n",
        "\n",
        "        v[\"W\"+str(i)] = beta2*v[\"W\"+str(i)] + (1-beta2)*grads[\"dW\"+str(i)]**2             #v_w update\n",
        "        v[\"b\"+str(i)] = beta2*v[\"b\"+str(i)] + (1-beta2)*grads[\"db\"+str(i)]**2             #v_b update\n",
        "\n",
        "        #cumulative average\n",
        "        m_w_hat = m[\"W\"+str(i)]/(1-np.power(beta1,n+1))\n",
        "        m_b_hat = m[\"b\"+str(i)]/(1-np.power(beta1,n+1))\n",
        "        v_w_hat = v[\"W\"+str(i)]/(1-np.power(beta2,n+1))\n",
        "        v_b_hat = v[\"b\"+str(i)]/(1-np.power(beta2,n+1))\n",
        "\n",
        "\n",
        "        update[\"W\"+str(i)]=lr*np.multiply(np.reciprocal(np.sqrt(v_w_hat+eps)),m_w_hat)\n",
        "        update[\"b\"+str(i)]=lr*np.multiply(np.reciprocal(np.sqrt(v_b_hat+eps)),m_b_hat)\n",
        "\n",
        "        parameters[\"W\"+str(i)] = (1-lr*reg)*parameters[\"W\"+str(i)] - update[\"W\"+str(i)]\n",
        "        parameters[\"b\"+str(i)] = (1-lr*reg)*parameters[\"b\"+str(i)] - update[\"b\"+str(i)]\n",
        "\n",
        "\n",
        "      steps=steps+1\n",
        "      if steps==10000:\n",
        "        if log:\n",
        "          acc,lossTot=calcAccLoss(parameters,X_train,Y_train,sizes,loss_type,activation,type=\"trng\",regu=reg)\n",
        "          accVal,lossTotVal=calcAccLoss(parameters,X_val,Y_val,sizes,loss_type,activation)\n",
        "\n",
        "          wandb.log({\"Accuracy\":acc,\"Loss\":lossTot,\"Accuracy_val\":accVal,\"Loss_val\":lossTotVal,\"Epoch\":n,\"n_datatrain\":j + minibatch_size+n*54000})\n",
        "        steps=0\n",
        "\n",
        "  return parameters\n",
        "\n",
        "\n",
        "#Nadam GD\n",
        "def nadam_GD(X_train,Y_train,activation,n_epoch,sizes,lr,reg,w_init,loss_type,minibatch_size=1,log=False) :\n",
        "  steps=0\n",
        "  parameters = network_init(sizes,w_init)\n",
        "  update = update_init(sizes)\n",
        "  m = update_init(sizes)\n",
        "  v = update_init(sizes)\n",
        "\n",
        "  beta1 = 0.9\n",
        "  beta2 = 0.999\n",
        "  eps = 1e-8\n",
        "\n",
        "  for n in range(n_epoch):\n",
        "\n",
        "    for j in range(0, X_train.shape[0], minibatch_size):\n",
        "      X_mini = X_train[j:j + minibatch_size]\n",
        "      Y_mini = Y_train[j:j + minibatch_size]\n",
        "      grads = grad_init(sizes)\n",
        "\n",
        "      for x,y in zip(X_mini,Y_mini):\n",
        "        y_hat,A,H = feed_forward(x,parameters,sizes,activation)\n",
        "        grads = back_prop(x,y,y_hat,grads,A,H,parameters,sizes,loss_type,activation,reg)\n",
        "\n",
        "      for i in range(1,len(sizes)-1) :                                                    #updating the parameters\n",
        "        m[\"W\"+str(i)] = beta1*m[\"W\"+str(i)] + (1-beta1)*grads[\"dW\"+str(i)]                #m_w update\n",
        "        m[\"b\"+str(i)] = beta1*m[\"b\"+str(i)] + (1-beta1)*grads[\"db\"+str(i)]                #m_b update\n",
        "\n",
        "        v[\"W\"+str(i)] = beta2*v[\"W\"+str(i)] + (1-beta2)*grads[\"dW\"+str(i)]**2             #v_w update\n",
        "        v[\"b\"+str(i)] = beta2*v[\"b\"+str(i)] + (1-beta2)*grads[\"db\"+str(i)]**2             #v_b update\n",
        "\n",
        "        #cumulative average\n",
        "        m_w_hat = m[\"W\"+str(i)]/(1-np.power(beta1,n+1))\n",
        "        m_b_hat = m[\"b\"+str(i)]/(1-np.power(beta1,n+1))\n",
        "        v_w_hat = v[\"W\"+str(i)]/(1-np.power(beta2,n+1))\n",
        "        v_b_hat = v[\"b\"+str(i)]/(1-np.power(beta2,n+1))\n",
        "\n",
        "\n",
        "        update[\"W\"+str(i)]=lr*np.multiply(np.reciprocal(np.sqrt(v_w_hat+eps)),(beta1*m_w_hat+(1-beta1)*grads[\"dW\"+str(i)]))*(1/(1-np.power(beta1,n+1)))\n",
        "        update[\"b\"+str(i)]=lr*np.multiply(np.reciprocal(np.sqrt(v_b_hat+eps)),(beta1*m_b_hat+(1-beta1)*grads[\"db\"+str(i)]))*(1/(1-np.power(beta1,n+1)))\n",
        "\n",
        "        parameters[\"W\"+str(i)] = (1-lr*reg)*parameters[\"W\"+str(i)] - update[\"W\"+str(i)]\n",
        "        parameters[\"b\"+str(i)] = (1-lr*reg)*parameters[\"b\"+str(i)] - update[\"b\"+str(i)]\n",
        "      steps=steps+1\n",
        "      if steps==10000:\n",
        "        if log:\n",
        "          acc,lossTot=calcAccLoss(parameters,X_train,Y_train,sizes,loss_type,activation,type=\"trng\",regu=reg)\n",
        "          accVal,lossTotVal=calcAccLoss(parameters,X_val,Y_val,sizes,loss_type,activation)\n",
        "\n",
        "          wandb.log({\"Accuracy\":acc,\"Loss\":lossTot,\"Accuracy_val\":accVal,\"Loss_val\":lossTotVal,\"Epoch\":n,\"n_datatrain\":j + minibatch_size+n*54000})\n",
        "        steps=0\n",
        "\n",
        "  return parameters"
      ],
      "metadata": {
        "id": "_WdC46-9Ljhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execution -- Main Function\n",
        "  "
      ],
      "metadata": {
        "id": "bSjNPV6-sJ3A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#function to select optimizer\n",
        "def do_GD(X_train,Y_train,optimizer,activation,hl_size,input_size,output_size,n_epoch,lr,reg,w_init,loss_type,minibatch_size=1,logging=False):\n",
        "  sizes = hl_size.copy()\n",
        "  sizes.insert(0,input_size)\n",
        "  sizes.append(output_size)\n",
        "\n",
        "  if optimizer==\"sgd\":\n",
        "    return(stochastic_GD(X_train,Y_train,activation,n_epoch,sizes,lr,reg,w_init,loss_type,minibatch_size=1,log=logging))\n",
        "  elif optimizer==\"momentum\":\n",
        "    return(momentum_GD(X_train,Y_train,activation,n_epoch,sizes,lr,reg,w_init,loss_type,1))\n",
        "  elif optimizer==\"nesterov\":\n",
        "    return(nesterov_accelerated_GD(X_train,Y_train,activation,n_epoch,sizes,lr,reg,w_init,loss_type,minibatch_size=1,log=logging))\n",
        "  elif optimizer==\"rmsprop\":\n",
        "    return(rmsprop_GD(X_train,Y_train,activation,n_epoch,sizes,lr,reg,w_init,loss_type,minibatch_size=1,log=logging))\n",
        "  elif optimizer==\"adam\":\n",
        "    return(adam_GD(X_train,Y_train,activation,n_epoch,sizes,lr,reg,w_init,loss_type,minibatch_size=1,log=logging))\n",
        "  elif optimizer==\"nadam\":\n",
        "    return(nadam_GD(X_train,Y_train,activation,n_epoch,sizes,lr,reg,w_init,loss_type,minibatch_size=1,log=logging))\n"
      ],
      "metadata": {
        "id": "Aa9B-D3FBNRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training function to sweep with wandb\n",
        "def train():\n",
        "\n",
        "  hyperparameter_defaults=dict(\n",
        "      input_size = 784,\n",
        "      output_size = 10,\n",
        "      n_epoch = 5,\n",
        "      n_hiddenlayer = 3,\n",
        "      hl= [64,64,64],\n",
        "      reg = 0.0005,\n",
        "      lr = 1e-3,\n",
        "      optimizer = \"momentum\",\n",
        "      batch_size = 64,\n",
        "      initialization = \"xavier\",\n",
        "      loss_type = \"cross_entropy\"\n",
        "\n",
        "  )\n",
        "\n",
        "  wandb.init(config=hyperparameter_defaults)\n",
        "\n",
        "  config=wandb.config\n",
        "  output_size=10\n",
        "  input_size = 784\n",
        "  config.hl=[config.hl_size for i in range(config.n_hiddenlayer)]   #hidden layer sizes array creation\n",
        "  parameters=do_GD(X_train, Y_train,config.optimizer,config.activation,config.hl,config.input_size,config.output_size,config.n_epoch,config.lr,config.reg,config.initialization,config.loss_type,config.batch_size,logging=True)\n"
      ],
      "metadata": {
        "id": "WRYhUCwYCn95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sweeper(sweep_config,proj_name):\n",
        "  sweep_id=wandb.sweep(sweep_config,project=proj_name)\n",
        "  wandb.agent(sweep_id,train,project=proj_name)"
      ],
      "metadata": {
        "id": "4v1g-XAWCx-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sweep dictionary\n",
        "sweep_config={\n",
        "    'method':'bayes',\n",
        "    'metric':{\n",
        "        'name':'accuracy',\n",
        "        'goal':'maximize'},\n",
        "\n",
        "}\n",
        "\n",
        "# def momentum_GD(X, Y, layer_sizes, mode='xavier', activation='relu', loss_type='cross_entropy', num_epochs=5, lr=0.1, mini_batch=1, reg=1):\n",
        "\n",
        "\n",
        "parameters_dict={\n",
        "    'optimizer':{\n",
        "        'values':['nadam','sgd', 'momentum', 'nesterov', 'rmsprop', 'adam']\n",
        "    },\n",
        "    'lr':{\n",
        "        'values':[1e-3,1e-5]\n",
        "    },\n",
        "    'reg':{\n",
        "        'values':[5e-4,0,5e-1]\n",
        "    },\n",
        "    'n_hiddenlayer':{\n",
        "        'values':[3,4,5]\n",
        "    },\n",
        "    'hl_size':{\n",
        "      'values':[128,32,64]\n",
        "    },\n",
        "    'batch_size':{\n",
        "        'values':[64,32,128]\n",
        "    },\n",
        "    'loss_type':{\n",
        "        'values':['cross_entropy','squared_error']\n",
        "    },\n",
        "    'initialization':{\n",
        "        'values':['xavier','random']\n",
        "    },\n",
        "    'activation':{\n",
        "        'values':['relu','sigmoid','tanh']\n",
        "    },\n",
        "    'n_epoch':{\n",
        "        'values':[5]\n",
        "    }\n",
        "}\n",
        "parameters_dict = {\n",
        "       'optimizer':{\n",
        "        'values':['momentum']\n",
        "    },\n",
        "    'lr':{\n",
        "        'values':[1e-3,1e-5]\n",
        "    },\n",
        "    'reg':{\n",
        "        'values':[5e-4,0,5e-1]\n",
        "    },\n",
        "    'n_hiddenlayer':{\n",
        "        'values':[3,4,5]\n",
        "    },\n",
        "    'hl_size':{\n",
        "      'values':[128,32,64]\n",
        "    },\n",
        "    'batch_size':{\n",
        "        'values':[64,32,128]\n",
        "    },\n",
        "    'loss_type':{\n",
        "        'values':['cross_entropy','squared_error']\n",
        "    },\n",
        "    'initialization':{\n",
        "        'values':['xavier','random']\n",
        "    },\n",
        "    'activation':{\n",
        "        'values':['relu','sigmoid','tanh']\n",
        "    },\n",
        "    'n_epoch':{\n",
        "        'values':[5]\n",
        "    }\n",
        "}\n",
        "sweep_config['parameters']=parameters_dict"
      ],
      "metadata": {
        "id": "nl5kzqOnCyhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "proj_name = \"Image_classification\"\n",
        "sweep_id=wandb.sweep(sweep_config,project=proj_name)"
      ],
      "metadata": {
        "id": "N7VyUMWjC1NM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sweeper(sweep_config,proj_name)"
      ],
      "metadata": {
        "id": "LZrtrkoVC19-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def do_momentum_based_GD()"
      ],
      "metadata": {
        "id": "Nx3CdE4pRawy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}